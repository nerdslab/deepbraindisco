{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook to load weights and extract activations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Please keep the file **architecture.py** in the same folder as this notebook, as well as the extracted **Data_Subset2** folder. Weights of the pre-trained model, i.e., **cnn_weights.pt** are available <a href=\"https://www.dropbox.com/s/q51rgk69cz90jn0/cnn_weights.pt?dl=0\" target=\"_blank\">here</a>. Please save them in the same folder as this notebook. Else, modify the paths appropriately!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from architecture import model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test for CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "if not train_on_gpu:\n",
    "    print('No GPU, training on CPU')\n",
    "else:\n",
    "    print('GPU found, training on GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Move model to GPU if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## custom dataset that includes image file paths, extends torchvision.datasets.ImageFolder\n",
    "class ImageFolderWithPaths(datasets.ImageFolder):\n",
    "\n",
    "    # override the __getitem__ method. this is the method dataloader calls\n",
    "    def __getitem__(self, index):\n",
    "        # this is what ImageFolder normally returns \n",
    "        original_tuple = super(ImageFolderWithPaths, self).__getitem__(index)\n",
    "        # the image file path\n",
    "        path = self.imgs[index][0]\n",
    "        # make a new tuple that includes original and the path\n",
    "        tuple_with_path = (original_tuple + (path,))\n",
    "        return tuple_with_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'Data_Subset2'\n",
    "train_dir = data_dir + '/Train'\n",
    "valid_dir = data_dir + '/Validation'\n",
    "test_dir = data_dir + '/Test'\n",
    "\n",
    "## number of subprocesses to use for data loading\n",
    "num_workers = 0\n",
    "## how many samples per batch to load\n",
    "batch_size = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert data to a normalized torch.FloatTensor\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "## choose the training and test datasets\n",
    "train_data = ImageFolderWithPaths(train_dir, transform = transform)\n",
    "valid_data = ImageFolderWithPaths(valid_dir, transform = transform)\n",
    "test_data = ImageFolderWithPaths(test_dir, transform = transform)\n",
    "\n",
    "## prepare data loaders (combine dataset and sampler)\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, num_workers=num_workers,shuffle=False)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_data, batch_size=batch_size, num_workers=num_workers,shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, num_workers=num_workers,shuffle=False)\n",
    "\n",
    "## specify the image classes\n",
    "classes = ['cortex', 'hypothalamus', 'striatum', 'vp', 'wm', 'zi']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collect activations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## note: this function makes the assumption that the batch size is a perfect divisor of\n",
    "## the number of samples in the dataset being used\n",
    "\n",
    "def collect_activations(loader,trained_model=model,bs=batch_size,reps_dim=64):\n",
    "    num_samples = (len(loader)*bs)\n",
    "    reps_mat = np.zeros((num_samples,reps_dim))\n",
    "    labels_list = np.zeros(num_samples)\n",
    "    locs_list = np.zeros((num_samples,2))\n",
    "    \n",
    "    cnt = 0\n",
    "    \n",
    "    trained_model.eval()\n",
    "    \n",
    "    for data, target, paths in loader:\n",
    "        paths_array = np.asarray(paths)\n",
    "    \n",
    "        # move tensors to GPU if CUDA is available\n",
    "        if train_on_gpu:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "    \n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output, latents = trained_model(data)\n",
    "    \n",
    "        for ii in range(len(paths_array)):\n",
    "            s = paths_array[ii]\n",
    "            underscores = ([pos for pos, char in enumerate(s) if char == '_'])\n",
    "            dot = (([pos for pos, char in enumerate(s) if char == '.']))\n",
    "            r = int(s[underscores[-2]+1:underscores[-1]])\n",
    "            c = int(s[underscores[-1]+1:dot[0]])\n",
    "\n",
    "            reps_mat[cnt] = latents[ii].cpu().detach().numpy()\n",
    "            locs_list[cnt] = r,c\n",
    "            labels_list[cnt] = target[ii].cpu().detach().numpy()\n",
    "            \n",
    "            cnt += 1\n",
    "        \n",
    "        \n",
    "    return reps_mat, labels_list, locs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activations_train, labels_train, locs_train = collect_activations(train_loader)\n",
    "activations_valid, labels_valid, locs_valid = collect_activations(valid_loader)\n",
    "activations_test, labels_test, locs_test = collect_activations(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
